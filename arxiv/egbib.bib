@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@inproceedings{bommasani2021opportunities,
      title={On the Opportunities and Risks of Foundation Models},
      author={Rishi Bommasani and Drew A. Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tramèr and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},
      year={2021},
      booktitle={arXiv 2108.07258}
}

@inproceedings{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      booktitle={arXiv 1810.04805}
}

@inproceedings{brown2020language,
      title={Language Models are Few-Shot Learners},
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      booktitle={arXiv 2005.14165}
}

@inproceedings{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision},
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      booktitle={arXiv 2103.00020}
}

@inproceedings{jia2021scaling,
      title={Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision},
      author={Chao Jia and Yinfei Yang and Ye Xia and Yi-Ting Chen and Zarana Parekh and Hieu Pham and Quoc V. Le and Yunhsuan Sung and Zhen Li and Tom Duerig},
      year={2021},
      booktitle={arXiv 2102.05918}
}

@misc{Wudao2,
  title = {Wu Dao 2.0},
 howpublished = {\url{https://gpt3demo.com/apps/wu-dao-20}}
}


@inproceedings{OrdonezKB11,
  author    = {Vicente Ordonez and
               Girish Kulkarni and
               Tamara L. Berg},
  title     = {Im2Text: Describing Images Using 1 Million Captioned Photographs},
  booktitle = {NeurIPS},
  year      = {2011}
}

@article{huang2020pixel,
  title={Pixel-{BERT}: Aligning image pixels with text by deep multi-modal transformers},
  author={Huang, Zhicheng and Zeng, Zhaoyang and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
  journal={arXiv preprint},
  year={2020}
}

@misc{XYZ-code,
  title = {A holistic representation toward integrative AI},
  author={Xuedong Huang},
  howpublished = {\url{https://www.microsoft.com/en-us/research/blog/a-holistic-representation-toward-integrative-ai/}}
  }
  
@misc{pathways,
title = {Introducing Pathways: A next-generation AI architecture},
author={Jeff Dean},
howpublished = {\url{https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/}},
}
  
 

@inproceedings{li2020unimo,
  title={Unimo: Towards unified-modal understanding and generation via cross-modal contrastive learning},
  author={Li, Wei and Gao, Can and Niu, Guocheng and Xiao, Xinyan and Liu, Hao and Liu, Jiachen and Wu, Hua and Wang, Haifeng},
  booktitle={Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2021}
}

@inproceedings{li2021align,
  title={Align before Fuse: Vision and Language Representation Learning with Momentum Distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath R and Gotmare, Akhilesh Deepak and Joty, Shafiq and Xiong, Caiming and Hoi, Steven},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@article{shen2021much,
  title={How Much Can CLIP Benefit Vision-and-Language Tasks?},
  author={Shen, Sheng and Li, Liunian Harold and Tan, Hao and Bansal, Mohit and Rohrbach, Anna and Chang, Kai-Wei and Yao, Zhewei and Keutzer, Kurt},
  journal={arXiv preprint},
  year={2021}
}

@inproceedings{GoyalKSBP16,
  author    = {Yash Goyal and
               Tejas Khot and
               Douglas Summers{-}Stay and
               Dhruv Batra and
               Devi Parikh},
  title     = {Making the {V} in {VQA} Matter: Elevating the Role of Image Understanding
               in Visual Question Answering},
  booktitle   = {CVPR},
  year      = {2017}
}

@inproceedings{changpinyo2021cc12m,
  title = {{Conceptual 12M}: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts},
  author = {Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle = {CVPR},
  year = {2021},
}

@article{liu2019roberta,
  title={Ro{BERT}a: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint},
  year={2019}
}

@inproceedings{dou2021empirical,
      title={An Empirical Study of Training End-to-End Vision-and-Language Transformers}, 
      author={Zi-Yi Dou and Yichong Xu and Zhe Gan and Jianfeng Wang and Shuohang Wang and Lijuan Wang and Chenguang Zhu and Nanyun and Peng and Zicheng Liu and Michael Zeng},
      year={2021},
      booktitle={arXiv 2111.02387},
}

@inproceedings{KimSK21,
  author    = {Wonjae Kim and
               Bokyung Son and
               Ildoo Kim},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {ViLT: Vision-and-Language Transformer Without Convolution or Region
               Supervision},
  booktitle = {ICML},
  year      = {2021}
}

@inproceedings{wang2021simvlm,
      title={SimVLM: Simple Visual Language Model Pretraining with Weak Supervision}, 
      author={Zirui Wang and Jiahui Yu and Adams Wei Yu and Zihang Dai and Yulia Tsvetkov and Yuan Cao},
      year={2021},
      booktitle={arXiv 2108.10904}
}

@inproceedings{xue2021probing,
  title={Probing Inter-modality: Visual Parsing with Self-Attention for Vision-Language Pre-training},
  author={Xue, Hongwei and Huang, Yupan and Liu, Bei and Peng, Houwen and Fu, Jianlong and Li, Houqiang and Luo, Jiebo},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{abs-2104-03135,
  author    = {Zhicheng Huang and
               Zhaoyang Zeng and
               Yupan Huang and
               Bei Liu and
               Dongmei Fu and
               Jianlong Fu},
  title     = {Seeing Out of tHe bOx: End-to-End Pre-training for Vision-Language
               Representation Learning},
  booktitle   = {CVPR},
  year      = {2021}
}

@inproceedings{abs-2104-02096,
  author    = {Zhiyuan Fang and
               Jianfeng Wang and
               Xiaowei Hu and
               Lijuan Wang and
               Yezhou Yang and
               Zicheng Liu},
  title     = {Compressing Visual-linguistic Model via Knowledge Distillation},
  booktitle   = {ICCV},
  year      = {2021}
}

@article{abs-2012-06946,
  author    = {Jianfeng Wang and
               Xiaowei Hu and
               Pengchuan Zhang and
               Xiujun Li and
               Lijuan Wang and
               Lei Zhang and
               Jianfeng Gao and
               Zicheng Liu},
  title     = {MiniVLM: {A} Smaller and Faster Vision-Language Model},
  journal   = {arXiv preprint arXiv:2012.06946},
  year      = {2020}
}

@inproceedings{00010BT0GZ18,
  author    = {Peter Anderson and
               Xiaodong He and
               Chris Buehler and
               Damien Teney and
               Mark Johnson and
               Stephen Gould and
               Lei Zhang},
  title     = {Bottom-Up and Top-Down Attention for Image Captioning and Visual Question
               Answering},
  booktitle = {CVPR},
  year      = {2018}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{liu2021video,
  title={Video swin transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  journal={arXiv preprint arXiv:2106.13230},
  year={2021}
}

@inproceedings{yu2018joint,
  title={A joint sequence fusion model for video question answering and retrieval},
  author={Yu, Youngjae and Kim, Jongseok and Kim, Gunhee},
  booktitle=ECCV,
  pages={471--487},
  year={2018}
}

@inproceedings{xu2016msr,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle=CVPR,
  pages={5288--5296},
  year={2016}
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle=CVPR,
  pages={9879--9889},
  year={2020}
}

@inproceedings{alayrac2020self,
  title={Self-Supervised MultiModal Versatile Networks.},
  author={Alayrac, Jean-Baptiste and Recasens, Adria and Schneider, Rosalia and Arandjelovic, Relja and Ramapuram, Jason and De Fauw, Jeffrey and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
  booktitle=NIPS,
  volume={2},
  number={6},
  pages={7},
  year={2020}
}

@inproceedings{akbari2021vatt,
  title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
  author={Akbari, Hassan and Yuan, Linagzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{chen2021multimodal,
  title={Multimodal Clustering Networks for Self-supervised Learning from Unlabeled Videos},
  author={Chen, Brian and Rouditchenko, Andrew and Duarte, Kevin and Kuehne, Hilde and Thomas, Samuel and Boggust, Angie and Panda, Rameswar and Kingsbury, Brian and Feris, Rogerio and Harwath, David and others},
  booktitle=ICCV,
  year={2021}
}

@inproceedings{xu2021videoclip,
  title={VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding},
  author={Xu, Hu and Ghosh, Gargi and Huang, Po-Yao and Okhonko, Dmytro and Aghajanyan, Armen and Metze, Florian and Zettlemoyer, Luke and Feichtenhofer, Christoph},
  booktitle={EMNLP},
  year={2021}
}

@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle=ICCV,
  year={2021}
}

@inproceedings{miech2019howto100m,
  title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle=ICCV,
  pages={2630--2640},
  year={2019}
}

@inproceedings{gemmeke2017audio,
  title={Audio set: An ontology and human-labeled dataset for audio events},
  author={Gemmeke, Jort F and Ellis, Daniel PW and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={ICASSP},
  pages={776--780},
  year={2017},
  organization={IEEE}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  pages={2556--2565},
  year={2018}
}

@inproceedings{arnab2021vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      booktitle={arXiv 2010.11929}
}

@article{liu2021Swin,
  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  journal={International Conference on Computer Vision (ICCV)},
  year={2021}
}

@InProceedings{Wu_2021_ICCV,
    author    = {Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
    title     = {CvT: Introducing Convolutions to Vision Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {22-31}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 volume = {30},
 year = {2017}
}

@inproceedings{yang2021focal,
    title={Focal Self-attention for Local-Global Interactions in Vision Transformers},
    author={Jianwei Yang and Chunyuan Li and Pengchuan Zhang and Xiyang Dai and Bin Xiao and Lu Yuan and Jianfeng Gao},
    year={2021},
    booktitle={arXiv 2107.00641}
}

@article{zhang2021multi,
  title={Multi-Scale Vision Longformer: A New Vision Transformer for High-Resolution Image Encoding},
  author={Zhang, Pengchuan and Dai, Xiyang and Yang, Jianwei and Xiao, Bin and Yuan, Lu and Zhang, Lei and Gao, Jianfeng},
  journal={ICCV 2021},
  year={2021}
}

@inproceedings{dong2021cswin,
      title={CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows},
      author={Xiaoyi Dong and Jianmin Bao and Dongdong Chen and Weiming Zhang and Nenghai Yu and Lu Yuan and Dong Chen and Baining Guo},
      year={2021},
      booktitle={arXiv 2107.00652}
}

@inproceedings{Dai_2021_CVPR,
    author    = {Dai, Xiyang and Chen, Yinpeng and Xiao, Bin and Chen, Dongdong and Liu, Mengchen and Yuan, Lu and Zhang, Lei},
    title     = {Dynamic Head: Unifying Object Detection Heads With Attentions},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {7373-7382}
}

@InProceedings{Dai_2021_ICCV,
    author    = {Dai, Xiyang and Chen, Yinpeng and Yang, Jianwei and Zhang, Pengchuan and Yuan, Lu and Zhang, Lei},
    title     = {Dynamic DETR: End-to-End Object Detection With Dynamic Attention},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {2988-2997}
}

@misc{lin2015microsoft,
      title={Microsoft {COCO:}: Common Objects in Context},
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      booktitle={arXiv 1405.0312}
}

@inproceedings{krishnavisualgenome,
  title={Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and Bernstein, Michael and Fei-Fei, Li},
  year = {2016},
  booktitle={arXiv 1602.07332}
}

@inproceedings{kay2017kinetics,
      title={The Kinetics Human Action Video Dataset},
      author={Will Kay and Joao Carreira and Karen Simonyan and Brian Zhang and Chloe Hillier and Sudheendra Vijayanarasimhan and Fabio Viola and Tim Green and Trevor Back and Paul Natsev and Mustafa Suleyman and Andrew Zisserman},
      year={2017},
      booktitle={arXiv 1705.06950}
}

@inproceedings{carreira2018short,
      title={A Short Note about Kinetics-600},
      author={Joao Carreira and Eric Noland and Andras Banki-Horvath and Chloe Hillier and Andrew Zisserman},
      year={2018},
      booktitle={arXiv 1808.01340}
}

@inproceedings{plummer2016flickr30k,
      title={Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models},
      author={Bryan A. Plummer and Liwei Wang and Chris M. Cervantes and Juan C. Caicedo and Julia Hockenmaier and Svetlana Lazebnik},
      year={2016},
      booktitle={arXiv 1505.04870}
}

@inproceedings{VQA,
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
title = {VQA: Visual Question Answering},
booktitle = {International Conference on Computer Vision (ICCV)},
year = {2015},
}

@article{DBLP:journals/corr/abs-1910-02054,
  author    = {Samyam Rajbhandari and
               Jeff Rasley and
               Olatunji Ruwase and
               Yuxiong He},
  title     = {ZeRO: Memory Optimization Towards Training {A} Trillion Parameter
               Models},
  journal   = {CoRR},
  year      = {2019},
  booktitle = {arXiv 1910.02054},
}


@inproceedings{gao2021scaling,
      title={Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup},
      author={Luyu Gao and Yunyi Zhang and Jiawei Han and Jamie Callan},
      year={2021},
      booktitle={arXiv 2101.06983},
}

@inproceedings{ramesh2021zeroshot,
      title={Zero-Shot Text-to-Image Generation},
      author={Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
      year={2021},
      booktitle={arXiv 2102.12092}
}

@inproceedings{Gupta_2019_CVPR,
author = {Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
title = {LVIS: A Dataset for Large Vocabulary Instance Segmentation},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@article{openimages,
  title={OpenImages: A public dataset for large-scale multi-label and multi-class image classification.},
  author={Krasin, Ivan and Duerig, Tom and Alldrin, Neil and Veit, Andreas and Abu-El-Haija, Sami
    and Belongie, Serge and Cai, David and Feng, Zheyun and Ferrari, Vittorio and Gomes, Victor
    and Gupta, Abhinav and Narayanan, Dhyanesh and Sun, Chen and Chechik, Gal and Murphy, Kevin},
  journal={Dataset available from https://github.com/openimages},
  year={2016}
}

@inproceedings{Shao_2019_ICCV,
author = {Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
title = {Objects365: A Large-Scale, High-Quality Dataset for Object Detection},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}

@inproceedings{russakovsky2015imagenet,
      title={ImageNet Large Scale Visual Recognition Challenge},
      author={Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
      year={2015},
      booktitle={arXiv 1409.0575}
}

@inproceedings{ZophGLCLC020_nips,
  author={Barret Zoph and Golnaz Ghiasi and Tsung-Yi Lin and Yin Cui and Hanxiao Liu and Ekin Dogus Cubuk and Quoc Le},
  title={Rethinking Pre-training and Self-training},
  year={2020},
  booktitle={NeurIPS}
}


@inproceedings{Xie_2020_CVPR,
author = {Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V.},
title = {Self-Training With Noisy Student Improves ImageNet Classification},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}


@article{ qi:imagebert,
  author = "Di Qi and Lin Su and Jia Song and Edward Cui and Taroon Bharti and Arun Sacheti",
  title = "ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data",
  journal = "arXiv preprintarXiv:2001.07966",
  year = "2020"
}


@inproceedings{ chen:uniter,
  author = "Yen-Chun Chen and Linjie Li and Licheng Yu and Ahmed El Kholy and Faisal Ahmed and Zhe Gan and Yu Cheng and Jingjing Liu",
  title = "UNITER: UNiversal Image-TExt Representation Learning",
  booktitle = "Proceedings of European Conference on Computer Vision",
  year = "2020"
}


@inproceedings{ chen:vsepooling,
  author = "Jiacheng Chen and Hexiang Hu and Hao Wu and Yuning Jiang and Changhu Wang",
  title = "Learning the Best Pooling Strategy for Visual Semantic Embedding",
  booktitle = "arXiv preprint arXiv:2011.04305",
  year = "2020"
}


@article{ yu:ernie-vil,
  author = {Yu, Fei and Tang, Jiji and Yin, Weichong and Sun, Yu and Tian, Hao and Wu, Hua and Wang, Haifeng},
  title = "ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph",
  journal = "arXiv preprint arXiv:2006.16934",
  year = "2020"
}


@inproceedings{ gan:villa,
  author = "Zhe Gan and Yen-Chun Chen and Linjie Li and Chen Zhu and Yu Cheng and Jingjing Liu",
  title = "Large-Scale Adversarial Training for Vision-and-Language Representation Learning",
  booktitle = "Proceedings of Neural Information Processing Systems",
  year = "2020"
}

@inproceedings{ li:oscar,
  author = "Xiujun Li and Xi Yin and Chunyuan Li and Pengchuan Zhang and Xiaowei Hu and Lei Zhang and Lijuan Wang and Houdong Hu and Li Dong and Furu Wei and Yejin Choi and Jianfeng Gao",
  title = "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks",
  booktitle = "Proceedings of European Conference on Computer Vision",
  year = "2020"
}

@inproceedings{kornblith2019better,
  title={Do better imagenet models transfer better?},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2661--2671},
  year={2019}
}

@inproceedings{6909656,
author={Berg, Thomas and Liu, Jiongxin and Lee, Seung Woo and Alexander, Michelle L. and Jacobs, David W. and Belhumeur, Peter N.},  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},   title={Birdsnap: Large-Scale Fine-Grained Visual Categorization of Birds},   year={2014},  pages={2019-2026}
}

@article{dosovitskiy2020vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={ICLR},
  year={2021}
}

@article{chen2020big,
  title={Big Self-Supervised Models are Strong Semi-Supervised Learners},
  author={Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2006.10029},
  year={2020}
}


@inproceedings{pmlr-v119-chen20j,
  title = 	 {A Simple Framework for Contrastive Learning of Visual Representations},
  author =       {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {1597--1607},
  year = 	 {2020},
  volume = 	 {119},
  month = 	 {13--18 Jul}
  }

@inproceedings{kolesnikov2020big,
      title={Big Transfer (BiT): General Visual Representation Learning},
      author={Alexander Kolesnikov and Lucas Beyer and Xiaohua Zhai and Joan Puigcerver and Jessica Yung and Sylvain Gelly and Neil Houlsby},
      year={2020},
      booktitle={arXiv 1912.11370}
}

@inproceedings{zhai2021scaling,
      title={Scaling Vision Transformers},
      author={Xiaohua Zhai and Alexander Kolesnikov and Neil Houlsby and Lucas Beyer},
      year={2021},
      booktitle={arXiv 2106.04560}
}

@inproceedings{dai2021coatnet,
      title={CoAtNet: Marrying Convolution and Attention for All Data Sizes},
      author={Zihang Dai and Hanxiao Liu and Quoc V. Le and Mingxing Tan},
      year={2021},
      booktitle={arXiv 2106.04803}
}

@inproceedings{ryoo2021tokenlearner,
      title={TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?},
      author={Michael S. Ryoo and AJ Piergiovanni and Anurag Arnab and Mostafa Dehghani and Anelia Angelova},
      year={2021},
      booktitle={arXiv 2106.11297}
}

@inproceedings{zhou2021simple,
      title={Simple multi-dataset detection},
      author={Xingyi Zhou and Vladlen Koltun and Philipp Krähenbühl},
      year={2021},
      booktitle={arXiv 2102.13086}
}

@inproceedings{Zhang_2021_CVPR,
    author    = {Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
    title     = {VinVL: Revisiting Visual Representations in Vision-Language Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {5579-5588}
}

@inproceedings{kamath2021mdetr,
      title={MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding},
      author={Aishwarya Kamath and Mannat Singh and Yann LeCun and Gabriel Synnaeve and Ishan Misra and Nicolas Carion},
      year={2021},
      booktitle={arXiv 2104.12763}
}

@inproceedings{yao2021filip,
      title={FILIP: Fine-grained Interactive Language-Image Pre-Training}, 
      author={Lewei Yao and Runhui Huang and Lu Hou and Guansong Lu and Minzhe Niu and Hang Xu and Xiaodan Liang and Zhenguo Li and Xin Jiang and Chunjing Xu},
      year={2021},
      booktitle={arXiv 2111.07783}
}

@inproceedings{RCNN2014,
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},
  title={Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
  year={2014},
  pages={580-587}
}

@inproceedings{Jianwei_UNICL2022,
      title={Unified Contrastive Learning in Image-Text-Label Space},
      author={Jianwei Yang and Chunyuan Li and Pengchuan Zhang and Bin Xiao and Ce Liu and Lu Yuan and Jianfeng Gao},
      year={2022},
      booktitle={arXiv In Preparation},
}

@inproceedings{harold_GLIP2021,
      title={Grounded Language-Image Pre-training},
      author={Liunian Harold Li and Pengchuan Zhang and Haotian Zhang and Jianwei Yang and Chunyuan Li and Yiwu Zhong and Lijuan Wang and Lu Yuan and Lei Zhang and Jenq-Neng Hwang and Kai-Wei Chang and Jianfeng Gao},
      year={2021},
      booktitle={arXiv In Preparation},
}

@inproceedings{Xu_2021_ICCV,
    author    = {Xu, Mengde and Zhang, Zheng and Hu, Han and Wang, Jianfeng and Wang, Lijuan and Wei, Fangyun and Bai, Xiang and Liu, Zicheng},
    title     = {End-to-End Semi-Supervised Object Detection With Soft Teacher},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {3060-3069}
}


@article{cdfsl,
  author    = {Yunhui Guo and
               Noel C. F. Codella and
               Leonid Karlinsky and
               John R. Smith and
               Tajana Rosing and
               Rog{\'{e}}rio Schmidt Feris},
  title     = {A New Benchmark for Evaluation of Cross-Domain Few-Shot Learning},
  journal   = {ECCV},
  year      = {2020},
  booktitle={arXiv 1912.07200},
}

@ARTICLE{eurosat,
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
  title={EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification}, 
  year={2019},
  volume={12},
  number={7},
  pages={2217-2226}
  }
  
@inproceedings{chestx,
      title={ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases}, 
      author={Xiaosong Wang and Yifan Peng and Le Lu and Zhiyong Lu and Mohammadhadi Bagheri and Ronald M. Summers},
      year={2017},
      booktitle={arXiv 1705.02315}
}


@article{isic2018,
  author    = {Noel C. F. Codella and
               Veronica Rotemberg and
               Philipp Tschandl and
               M. Emre Celebi and
               Stephen W. Dusza and
               David A. Gutman and
               Brian Helba and
               Aadi Kalloo and
               Konstantinos Liopyris and
               Michael A. Marchetti and
               Harald Kittler and
               Allan Halpern},
  title     = {Skin Lesion Analysis Toward Melanoma Detection 2018: {A} Challenge
               Hosted by the International Skin Imaging Collaboration {(ISIC)}},
  volume    = {abs/1902.03368},
  year      = {2019},
  booktitle={arXiv 1902.03368}
}


@article{plantdisease,
  author    = {Sharada P Mohanty  and
               David P Hughes  and
               Marcel Salathe},
  title     = {Using Deep Learning for Image-Based Plant Disease Detection},
  journal   = {Front Plant Sci},
  volume    = {7},
  year      = {2016}
}

@article{ham10000,
  author    = {Philipp Tschandl and
               Cliff Rosendahl  and
               Harald Kittler},
  title     = {The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions},
  journal   = {Nature Scientific Data},
  volume    = {5},
  year      = {2018}

}


@article{cdfsltop,
  author    = {Bingyu Liu and
               Zhen Zhao and
               Zhenpeng Li and
               Jianan Jiang and
               Yuhong Guo and
               Jieping Ye},
  title     = {Feature Transformation Ensemble Model with Batch Spectral Regularization
               for Cross-Domain Few-Shot Classification},
  year      = {2020},
  booktitle={arXiv 2005.08463}
}

@inproceedings{bansal2018zero,
  title={Zero-shot object detection},
  author={Bansal, Ankan and Sikka, Karan and Sharma, Gaurav and Chellappa, Rama and Divakaran, Ajay},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={384--400},
  year={2018}
}

@INPROCEEDINGS{resnet2016,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  pages={770-778}
  }